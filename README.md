# rationalizing-neural-predictions

This project is related to "Interpretable Learning" aims to predict the ratings a user would have given to a product based on his textual reviews. 
In addition to predicting, justifications also have to be provided by the model in terms of excerpts from the text.

This project experiments on two methods. 
First method uses attention weights to find the areas where model focuses on the text. Highly focused text are given justification for prediction.
Second method is an implementation of the paper on the same title (https://arxiv.org/abs/1606.04155).
